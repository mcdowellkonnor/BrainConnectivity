{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6193183f",
   "metadata": {},
   "source": [
    "# 08_Deep_Learning\n",
    "\n",
    "- 2025-09-08\n",
    "- Aim to establish optimal model scores for comparison to SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pca import pca\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from random import randint\n",
    "from pqdm.threads import pqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b93872",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = None\n",
    "if os.path.isfile(\"data/data.pkl\"):\n",
    "    data_df = pd.read_pickle(\"data/data.pkl\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(data_df.head().to_markdown())\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and load data\n",
    "ad_df = data_df[\n",
    "    data_df[\"Diagnosis\"].isin([\"AD\", \"HC\"]) & (data_df[\"Harmonized\"].notna())\n",
    "].copy()\n",
    "\n",
    "x_ad = np.vstack(ad_df[\"EVC\"].values)\n",
    "y_ad = ad_df[\"Diagnosis\"].map({\"AD\": 1, \"HC\": 0}).values\n",
    "\n",
    "# tbi_df = data_df[\n",
    "#     data_df[\"Diagnosis\"].isin([\"NEG\", \"POS\"]) & (data_df[\"Harmonized\"].notna())\n",
    "# ].copy()\n",
    "# x_tbi = np.vstack(tbi_df[\"EVC\"].values)\n",
    "# y_tbi = tbi_df[\"Diagnosis\"].map({\"POS\": 1, \"NEG\": 0}).values\n",
    "\n",
    "# Scale X\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_ad)\n",
    "x_ad = scaler.transform(x_ad)\n",
    "# x_tbi = scaler.transform(x_tbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d432d4",
   "metadata": {},
   "source": [
    "#### PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain PCA\n",
    "ad_pca = pca()\n",
    "x_ad_pca = ad_pca.fit_transform(x_ad)\n",
    "\n",
    "ad_pca.plot()\n",
    "print(x_ad_pca[\"topfeat\"].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166673da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pca.biplot3d(n_feat=10, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ad81f",
   "metadata": {},
   "source": [
    "### MLP Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43af3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extremely basic MLP for overfit\n",
    "clf = MLPClassifier(\n",
    "    random_state=RANDOM_STATE, solver=\"lbfgs\", hidden_layer_sizes=(64, 32)\n",
    ")\n",
    "clf.fit(x_ad, y_ad)\n",
    "clf.score(x_ad, y_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout Test with basic MLP\n",
    "ratios = np.arange(0.05, 1, 0.05)\n",
    "\n",
    "\n",
    "def test_ratio(ratio):\n",
    "    scores_at_ratio = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            x_ad, y_ad, random_state=randint(1, 100000), test_size=ratio\n",
    "        )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        clf = MLPClassifier(\n",
    "            random_state=RANDOM_STATE, solver=\"lbfgs\", hidden_layer_sizes=(64, 32)\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        scores_at_ratio.append(clf.score(X_test, y_test))\n",
    "\n",
    "    return scores_at_ratio\n",
    "\n",
    "\n",
    "scores = pqdm(ratios, test_ratio, n_jobs=2)\n",
    "\n",
    "y = np.mean(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ratios, y, \"k-\")\n",
    "plt.fill_between(\n",
    "    ratios, y - np.std(scores, axis=1), y + np.std(scores, axis=1), alpha=0.5\n",
    ")\n",
    "plt.xlabel(\"Train/Test Size Ratio\")\n",
    "plt.ylabel(\"Model Score\")\n",
    "plt.title(\"Effect of Train/Test Size on Model Performance\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e79acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of alpha, reinvent cv wheel\n",
    "scores = []\n",
    "scores_tbi = []\n",
    "alpha = np.geomspace(1e-8, 10, num=50)\n",
    "\n",
    "\n",
    "def test_alpha(a):\n",
    "    scores_at_alpha = []\n",
    "    scores_at_alpha_tbi = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            x_ad, y_ad, random_state=randint(1, 100000), test_size=0.2\n",
    "        )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_tbi = scaler.transform(x_tbi)\n",
    "\n",
    "        clf = MLPClassifier(\n",
    "            alpha=a, max_iter=1000, solver=\"lbfgs\", hidden_layer_sizes=(64, 32)\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        scores_at_alpha.append(clf.score(X_test, y_test))\n",
    "        scores_at_alpha_tbi.append(clf.score(X_tbi, y_tbi))\n",
    "\n",
    "    return (scores_at_alpha, scores_at_alpha_tbi)\n",
    "\n",
    "\n",
    "results = pqdm(alpha, test_alpha, n_jobs=12)\n",
    "scores, scores_tbi = zip(*results)\n",
    "\n",
    "y = np.mean(scores, axis=1)\n",
    "alpha_y_tbi = np.mean(scores_tbi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3954b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(alpha, y, \"k-\", label=\"AD/HC\")\n",
    "plt.fill_between(\n",
    "    alpha,\n",
    "    y - np.std(scores, axis=1),\n",
    "    y + np.std(scores, axis=1),\n",
    "    alpha=0.5,\n",
    "    color=\"black\",\n",
    ")\n",
    "\n",
    "plt.semilogx(alpha, alpha_y_tbi, \"r-\", label=\"TBI+/TBI-\")\n",
    "plt.fill_between(\n",
    "    alpha,\n",
    "    alpha_y_tbi - np.std(scores_tbi, axis=1),\n",
    "    alpha_y_tbi + np.std(scores_tbi, axis=1),\n",
    "    alpha=0.5,\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"MLP Alpha\")\n",
    "plt.ylabel(\"Model Score\")\n",
    "plt.title(\"Effect of MLP Alpha Value on Model Performance\")\n",
    "plt.ylim(0, 1)\n",
    "# plt.xlim(0, 10)\n",
    "plt.grid(\"both\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
