{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Feature Analysis\n",
    "\n",
    "Given a specific modeling approach, attempt to determine which features are attended for classification results. Additionally, attempt to obtain Shapley values for the features and present on a figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "data_df = None\n",
    "if os.path.isfile(\"data/data.pkl\"):\n",
    "    data_df = pd.read_pickle(\"data/data.pkl\")\n",
    "else:\n",
    "    print(\"Load Data\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_df = data_df[(data_df[\"Study\"] != \"TBI\") & (data_df[\"Harmonized\"].notna())]\n",
    "ad_evc = np.vstack(ad_df[\"EVC\"])\n",
    "\n",
    "# SPECIFIC_NODES = [2, 7, 83, 86, 120, 167]\n",
    "# ad_evc = ad_evc[:, SPECIFIC_NODES]\n",
    "\n",
    "ad_class = np.where(ad_df[\"Diagnosis\"] == \"AD\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "clf = svm.SVC(\n",
    "    kernel=\"sigmoid\",\n",
    "    class_weight=\"balanced\",\n",
    "    probability=True,\n",
    "    random_state=RANDOM_STATE,\n",
    "    max_iter=100000,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ad_evc_scaled = scaler.fit_transform(ad_evc)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    ad_evc_scaled, ad_class, random_state=RANDOM_STATE, stratify=ad_class\n",
    ")\n",
    "feature_variance = pd.DataFrame(x_train).var(axis=0)\n",
    "print(\"Feature Variance:\\n\", feature_variance)\n",
    "clf.fit(x_train, y_train)\n",
    "# best_model = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    \"C\": np.logspace(-2, 2, 10),\n",
    "    \"kernel\": [\"linear\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": np.logspace(-4, 1, 10),\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=svc_params,\n",
    "    cv=2,\n",
    "    refit=True,\n",
    "    verbose=9,\n",
    "    n_jobs=-1,\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "gridsearch.fit(x_train, y_train)\n",
    "best_model = gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(best_model.predict_proba, x_train)\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "shap_pos_class = shap_values[:, :, 1]\n",
    "shap_values_pos = shap.Explanation(\n",
    "    values=shap_pos_class,\n",
    "    base_values=explainer.expected_value[1],\n",
    "    data=x_test,\n",
    "    feature_names=[f\"Feature {i+1}\" for i in range(x_test.shape[1])],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Model Parameters:\", gridsearch.best_params_)\n",
    "\n",
    "y_predict = best_model.predict(x_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_predict))\n",
    "\n",
    "importances = permutation_importance(best_model, x_test, y_test, scoring=\"accuracy\")\n",
    "print(\"Feature Importances:\\n\", importances.importances_mean)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_pos_class,\n",
    "    x_test,\n",
    "    feature_names=[f\"Feature {i+1}\" for i in range(x_test.shape[1])],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values_pos.abs.max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plots display individual predictions, so they expect a single row\n",
    "# of an Explanation object as input\n",
    "sample_ind = 0\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_pos_class[sample_ind],\n",
    "        base_values=explainer.expected_value[1],\n",
    "        data=x_test[sample_ind],\n",
    "        feature_names=[f\"Feature {i+1}\" for i in range(x_test.shape[1])],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, lasso_path, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = Lasso(alpha=1)\n",
    "reg.fit(x_train, y_train)\n",
    "print(\"R squared training set\", round(reg.score(x_train, y_train) * 100, 2))\n",
    "print(\"R squared test set\", round(reg.score(x_test, y_test) * 100, 2))\n",
    "\n",
    "# Training data\n",
    "pred_train = reg.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train, pred_train)\n",
    "print(\"MSE training set\", round(mse_train, 2))\n",
    "\n",
    "# Test data\n",
    "pred = reg.predict(x_test)\n",
    "mse_test = mean_squared_error(y_test, pred)\n",
    "print(\"MSE test set\", round(mse_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing regularization path using the lasso...\")\n",
    "eps = 5e-2\n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(x_train, y_train, eps=eps)\n",
    "\n",
    "plt.figure(1)\n",
    "for coef_lasso in coefs_lasso:\n",
    "    l1 = plt.semilogx(alphas_lasso, coef_lasso)\n",
    "\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.title(\"Lasso Paths\")\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "lasso_cv = LassoCV(cv=skf, random_state=RANDOM_STATE, max_iter=10000)\n",
    "lasso_cv.fit(x_train, y_train)\n",
    "best_alpha = lasso_cv.alpha_\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "plt.axvline(x=best_alpha, color=\"red\", linestyle=\"dotted\", label=f\"Alpha: {best_alpha}\")\n",
    "\n",
    "lasso_best = Lasso(alpha=best_alpha)\n",
    "lasso_best.fit(x_train, y_train)\n",
    "coefficients = lasso_best.coef_\n",
    "nonzero_indices = np.where(coefficients != 0)[0]\n",
    "\n",
    "sorted_data = sorted(\n",
    "    [\n",
    "        (idx + 1, coef)\n",
    "        for idx, coef in zip(nonzero_indices, coefficients[nonzero_indices])\n",
    "    ],\n",
    "    key=lambda x: abs(x[1]),\n",
    "    reverse=True,\n",
    ")\n",
    "coefficients_df = pd.DataFrame(sorted_data, columns=[\"Feature Index\", \"Coefficient\"])\n",
    "\n",
    "print(\"R squared training set\", round(lasso_best.score(x_train, y_train) * 100, 2))\n",
    "print(\"R squared test set\", round(lasso_best.score(x_test, y_test) * 100, 2))\n",
    "print(\"MSE test:\", mean_squared_error(y_test, lasso_best.predict(x_test)))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(lasso_cv.alphas_, lasso_cv.mse_path_, \":\")\n",
    "plt.plot(\n",
    "    lasso_cv.alphas_,\n",
    "    lasso_cv.mse_path_.mean(axis=-1),\n",
    "    \"k\",\n",
    "    label=\"Average across the folds\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.axvline(lasso_cv.alpha_, linestyle=\"--\", color=\"k\", label=\"alpha: CV estimate\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"alphas\")\n",
    "plt.ylabel(\"Mean square error\")\n",
    "plt.title(\"Mean square error on each fold\")\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "# ymin, ymax = 50000, 250000\n",
    "# plt.ylim(ymin, ymax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "f_stat, p_values = f_regression(ad_evc_scaled, ad_class)\n",
    "feature_data = pd.DataFrame(\n",
    "    {\"Feature Index\": range(1, len(p_values) + 1), \"P-Value\": p_values}\n",
    ")\n",
    "\n",
    "significant_features = feature_data[feature_data[\"P-Value\"] < 0.05].sort_values(\n",
    "    by=\"P-Value\"\n",
    ")\n",
    "significant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pygam import LogisticGAM, s\n",
    "# import scipy.sparse\n",
    "\n",
    "# def to_array(self):\n",
    "#     return self.toarray()\n",
    "\n",
    "# scipy.sparse.spmatrix.A = property(to_array)\n",
    "\n",
    "# np.int = np.int32\n",
    "# np.float = np.float64\n",
    "# np.bool = np.bool_\n",
    "# x_t = pd.DataFrame(x_train)\n",
    "# print(x_t)\n",
    "# gam = LogisticGAM(verbose=True).fit(x_t, y_train)\n",
    "# gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gam_opt = LogisticGAM().gridsearch(x_train, y_train)\n",
    "# gam_opt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.float_format', '{:.10f}'.format)\n",
    "# feature_data.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to TBI Directly\n",
    "\n",
    "Applies the grid-search model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tbi_df = data_df[data_df[\"Study\"] == \"TBI\"]\n",
    "tbi_evc = np.vstack(tbi_df[\"EVC\"])\n",
    "\n",
    "# tbi_evc = tbi_evc[:, SPECIFIC_NODES]\n",
    "\n",
    "tbi_class = np.where(tbi_df[\"Diagnosis\"] == \"POS\", 1, 0)\n",
    "tbi_scaled = scaler.fit_transform(tbi_evc)\n",
    "\n",
    "y_pred = best_model.predict(tbi_evc)\n",
    "accuracy = accuracy_score(tbi_class, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(tbi_class, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
